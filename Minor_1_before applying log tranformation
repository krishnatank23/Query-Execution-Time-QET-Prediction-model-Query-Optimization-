{"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVR\n","from xgboost import XGBRegressor\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","import joblib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy import stats\n"],"metadata":{"id":"NwLh1scC-pYI","executionInfo":{"status":"ok","timestamp":1756789880220,"user_tz":-330,"elapsed":7,"user":{"displayName":"2024 18056","userId":"06233739373208717586"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Load Dataset\n","# -------------------------\n","df = pd.read_csv(\"/content/imdb_query_plan_features_merged.csv\")\n","target = \"actual_execution_time\"\n","\n","drop_leaky_features = [\n","    \"total_actual_rows\", \"total_actual_loops\", \"total_actual_time_node\",\n","    \"output_rows\", \"rows_estimate_error\", \"rows_estimate_ratio\",\n","    \"output_row_estimation_error\", \"output_row_estimation_ratio\",\n","    \"cost_time_ratio\", \"sum_node_actual_time_vs_total_actual_time_ratio\",\n","    target, \"query_id\"\n","]\n","X = df.drop(columns=drop_leaky_features, errors=\"ignore\")\n","y = df[target]\n"],"metadata":{"id":"2ghMZFgZ-uyS","executionInfo":{"status":"ok","timestamp":1756789881670,"user_tz":-330,"elapsed":40,"user":{"displayName":"2024 18056","userId":"06233739373208717586"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# Train / Validation / Test Split\n","# =========================\n","X_train_val, X_test, y_train_val, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train_val, y_train_val, test_size=0.25, random_state=42\n",")\n","\n","# =========================\n","# Handle Missing Values\n","# =========================\n","imputer = SimpleImputer(strategy=\"median\")\n","X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n","X_val   = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns, index=X_val.index)\n","X_test  = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns, index=X_test.index)\n","\n","# =========================\n","# Utility Functions\n","# =========================\n","def adjusted_r2(r2, n, k):\n","    return 1 - (1-r2) * (n-1)/(n-k-1)\n","\n","def safe_expm1(arr, cap=700):\n","    \"\"\"Prevent overflow when converting from log-space.\"\"\"\n","    arr = np.clip(arr, None, cap)  # cap very large values\n","    return np.expm1(arr)\n","\n","def accuracy_within_tolerance(y_true, y_pred, tol=0.10):\n","    \"\"\"Compute accuracy within tolerance in original space.\"\"\"\n","    y_true, y_pred = safe_expm1(y_true), safe_expm1(y_pred)\n","    tolerance = tol * np.abs(y_true)\n","    within_tol = np.abs(y_pred - y_true) <= tolerance\n","    return np.mean(within_tol) * 100\n","\n","def evaluate_model_full(name, model, X_train, y_train, X_val, y_val, X_test, y_test):\n","    results = {}\n","    for split, X_, y_ in [(\"Train\", X_train, y_train),\n","                          (\"Validation\", X_val, y_val),\n","                          (\"Test\", X_test, y_test)]:\n","        y_pred = model.predict(X_)\n","\n","        # Metrics in log-space\n","        mse = mean_squared_error(y_, y_pred)\n","        rmse = np.sqrt(mse)\n","        mae = mean_absolute_error(y_, y_pred)\n","        r2 = r2_score(y_, y_pred)\n","        adj_r2 = adjusted_r2(r2, X_.shape[0], X_.shape[1])\n","\n","        # Metrics in original space\n","        acc10 = accuracy_within_tolerance(y_, y_pred, tol=0.10)\n","        acc20 = accuracy_within_tolerance(y_, y_pred, tol=0.20)\n","        acc30 = accuracy_within_tolerance(y_, y_pred, tol=0.30)\n","\n","        results[split] = {\n","            \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae,\n","            \"R2\": r2, \"AdjR2\": adj_r2,\n","            \"Acc@10%\": acc10, \"Acc@20%\": acc20, \"Acc@30%\": acc30\n","        }\n","\n","    print(f\"\\nðŸ“Š {name} Results:\")\n","    for split in [\"Train\", \"Validation\", \"Test\"]:\n","        metrics = results[split]\n","        print(f\"  {split}: MSE={metrics['MSE']:.2f}, RMSE={metrics['RMSE']:.2f}, \"\n","              f\"MAE={metrics['MAE']:.2f}, RÂ²={metrics['R2']:.4f}, \"\n","              f\"AdjRÂ²={metrics['AdjR2']:.4f}, \"\n","              f\"Acc@10%={metrics['Acc@10%']:.2f}%, \"\n","              f\"Acc@20%={metrics['Acc@20%']:.2f}%, \"\n","              f\"Acc@30%={metrics['Acc@30%']:.2f}%\")\n","    return results\n","\n","def grid_search_model(name, model, param_grid, X_train, y_train):\n","    grid = GridSearchCV(model, param_grid, cv=3, scoring=\"r2\", n_jobs=-1, verbose=1)\n","    grid.fit(X_train, y_train)   # âœ… keep DataFrames to avoid warnings\n","    print(f\"\\nðŸ”Ž {name} Best Params: {grid.best_params_}\")\n","    return grid.best_estimator_\n","\n","# =========================\n","# Models + Hyperparameter Grids\n","# =========================\n","param_grids = {\n","    \"Random Forest\": {\n","        \"n_estimators\": [100, 200],\n","        \"max_depth\": [10, None],\n","        \"max_features\": [\"sqrt\", \"log2\"]\n","    },\n","    \"XGBoost\": {\n","        \"n_estimators\": [100, 200],\n","        \"max_depth\": [6, 10],\n","        \"learning_rate\": [0.05, 0.1],\n","        \"subsample\": [0.8, 1.0]\n","    },\n","    \"Gradient Boosting\": {\n","        \"n_estimators\": [100, 200],\n","        \"max_depth\": [4, 6],\n","        \"learning_rate\": [0.05, 0.1]\n","    },\n","    \"Linear Regression\": {\n","        \"linearregression__fit_intercept\": [True, False],\n","        \"linearregression__positive\": [True, False]\n","    },\n","    \"SVR\": {\n","        \"svr__kernel\": [\"linear\", \"rbf\"],\n","        \"svr__C\": [0.1, 1, 10],\n","        \"svr__gamma\": [\"scale\", \"auto\"]\n","    }\n","}\n","\n","# =========================\n","# Train & Evaluate Models\n","# =========================\n","results = []\n","\n","# Random Forest\n","rf_best = grid_search_model(\"Random Forest\",\n","    RandomForestRegressor(random_state=42, n_jobs=-1),\n","    param_grids[\"Random Forest\"], X_train, y_train)\n","rf_metrics = evaluate_model_full(\"Random Forest\", rf_best, X_train, y_train, X_val, y_val, X_test, y_test)\n","results.append((\"Random Forest\", rf_best, rf_metrics[\"Validation\"][\"R2\"]))\n","\n","# XGBoost\n","xgb_best = grid_search_model(\"XGBoost\",\n","    XGBRegressor(random_state=42, n_jobs=-1, eval_metric=\"rmse\"),\n","    param_grids[\"XGBoost\"], X_train, y_train)\n","xgb_metrics = evaluate_model_full(\"XGBoost\", xgb_best, X_train, y_train, X_val, y_val, X_test, y_test)\n","results.append((\"XGBoost\", xgb_best, xgb_metrics[\"Validation\"][\"R2\"]))\n","\n","# Gradient Boosting\n","gb_best = grid_search_model(\"Gradient Boosting\",\n","    GradientBoostingRegressor(random_state=42),\n","    param_grids[\"Gradient Boosting\"], X_train, y_train)\n","gb_metrics = evaluate_model_full(\"Gradient Boosting\", gb_best, X_train, y_train, X_val, y_val, X_test, y_test)\n","results.append((\"Gradient Boosting\", gb_best, gb_metrics[\"Validation\"][\"R2\"]))\n","\n","# Linear Regression\n","lr_pipe = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"linearregression\", LinearRegression())\n","])\n","lr_best = grid_search_model(\"Linear Regression\", lr_pipe,\n","                            param_grids[\"Linear Regression\"], X_train, y_train)\n","lr_metrics = evaluate_model_full(\"Linear Regression\", lr_best, X_train, y_train, X_val, y_val, X_test, y_test)\n","results.append((\"Linear Regression\", lr_best, lr_metrics[\"Validation\"][\"R2\"]))\n","\n","# SVR\n","svr_pipe = Pipeline([\n","    (\"scaler\", StandardScaler()),\n","    (\"svr\", SVR())\n","])\n","svr_best = grid_search_model(\"SVR\", svr_pipe, param_grids[\"SVR\"], X_train, y_train)\n","svr_metrics = evaluate_model_full(\"SVR\", svr_best, X_train, y_train, X_val, y_val, X_test, y_test)\n","results.append((\"SVR\", svr_best, svr_metrics[\"Validation\"][\"R2\"]))\n","\n","# =========================\n","# Select & Save Best Model\n","# =========================\n","best_model_name, best_model, _ = max(results, key=lambda x: x[2])\n","print(f\"\\nðŸ† Best Model: {best_model_name}\")\n","joblib.dump(best_model, f\"best_{best_model_name.replace(' ', '_').lower()}.pkl\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oLC_q57Uvnr5","executionInfo":{"status":"ok","timestamp":1756790946543,"user_tz":-330,"elapsed":180328,"user":{"displayName":"2024 18056","userId":"06233739373208717586"}},"outputId":"05d19ca2-90fb-46b0-8398-b3255744dc71"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 3 folds for each of 8 candidates, totalling 24 fits\n","\n","ðŸ”Ž Random Forest Best Params: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}\n","\n","ðŸ“Š Random Forest Results:\n","  Train: MSE=196819.23, RMSE=443.64, MAE=116.32, RÂ²=0.9838, AdjRÂ²=0.9837, Acc@10%=20.21%, Acc@20%=25.31%, Acc@30%=29.90%\n","  Validation: MSE=1405832.39, RMSE=1185.68, MAE=311.10, RÂ²=0.8814, AdjRÂ²=0.8788, Acc@10%=14.06%, Acc@20%=16.49%, Acc@30%=18.29%\n","  Test: MSE=1239872.75, RMSE=1113.50, MAE=294.70, RÂ²=0.8880, AdjRÂ²=0.8856, Acc@10%=14.87%, Acc@20%=17.98%, Acc@30%=19.98%\n","Fitting 3 folds for each of 16 candidates, totalling 48 fits\n","\n","ðŸ”Ž XGBoost Best Params: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n","\n","ðŸ“Š XGBoost Results:\n","  Train: MSE=28671.95, RMSE=169.33, MAE=72.51, RÂ²=0.9976, AdjRÂ²=0.9976, Acc@10%=0.21%, Acc@20%=0.50%, Acc@30%=0.77%\n","  Validation: MSE=1721664.07, RMSE=1312.12, MAE=344.42, RÂ²=0.8547, AdjRÂ²=0.8516, Acc@10%=0.12%, Acc@20%=0.31%, Acc@30%=0.62%\n","  Test: MSE=1587087.11, RMSE=1259.80, MAE=333.84, RÂ²=0.8566, AdjRÂ²=0.8535, Acc@10%=0.25%, Acc@20%=0.37%, Acc@30%=0.68%\n","Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n","/tmp/ipython-input-2530657535.py:28: RuntimeWarning: overflow encountered in expm1\n","  return np.expm1(arr)\n"]},{"output_type":"stream","name":"stdout","text":["\n","ðŸ”Ž Gradient Boosting Best Params: {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 200}\n","\n","ðŸ“Š Gradient Boosting Results:\n","  Train: MSE=377998.64, RMSE=614.82, MAE=226.99, RÂ²=0.9689, AdjRÂ²=0.9687, Acc@10%=10.87%, Acc@20%=10.89%, Acc@30%=10.93%\n","  Validation: MSE=1475430.24, RMSE=1214.67, MAE=347.61, RÂ²=0.8755, AdjRÂ²=0.8728, Acc@10%=10.89%, Acc@20%=10.95%, Acc@30%=10.95%\n","  Test: MSE=1278623.02, RMSE=1130.76, MAE=324.44, RÂ²=0.8845, AdjRÂ²=0.8820, Acc@10%=10.58%, Acc@20%=10.58%, Acc@30%=10.64%\n","Fitting 3 folds for each of 4 candidates, totalling 12 fits\n","\n","ðŸ”Ž Linear Regression Best Params: {'linearregression__fit_intercept': True, 'linearregression__positive': False}\n","\n","ðŸ“Š Linear Regression Results:\n","  Train: MSE=4037821.39, RMSE=2009.43, MAE=1254.11, RÂ²=0.6677, AdjRÂ²=0.6653, Acc@10%=11.66%, Acc@20%=11.66%, Acc@30%=11.66%\n","  Validation: MSE=3894605.05, RMSE=1973.48, MAE=1241.38, RÂ²=0.6714, AdjRÂ²=0.6643, Acc@10%=11.39%, Acc@20%=11.39%, Acc@30%=11.39%\n","  Test: MSE=3293439.27, RMSE=1814.78, MAE=1231.39, RÂ²=0.7025, AdjRÂ²=0.6960, Acc@10%=11.14%, Acc@20%=11.14%, Acc@30%=11.14%\n","Fitting 3 folds for each of 12 candidates, totalling 36 fits\n","\n","ðŸ”Ž SVR Best Params: {'svr__C': 10, 'svr__gamma': 'auto', 'svr__kernel': 'rbf'}\n","\n","ðŸ“Š SVR Results:\n","  Train: MSE=11414171.11, RMSE=3378.49, MAE=956.99, RÂ²=0.0606, AdjRÂ²=0.0539, Acc@10%=6.47%, Acc@20%=8.22%, Acc@30%=9.05%\n","  Validation: MSE=11078559.15, RMSE=3328.45, MAE=944.29, RÂ²=0.0653, AdjRÂ²=0.0450, Acc@10%=5.60%, Acc@20%=6.60%, Acc@30%=7.22%\n","  Test: MSE=10345334.60, RMSE=3216.42, MAE=931.76, RÂ²=0.0654, AdjRÂ²=0.0452, Acc@10%=5.16%, Acc@20%=6.53%, Acc@30%=7.47%\n","\n","ðŸ† Best Model: Random Forest\n"]},{"output_type":"execute_result","data":{"text/plain":["['best_random_forest.pkl']"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"2NuZeWLgCf71"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1MlJoHaTI1NglxZPPQtOxJiB7yILAZPX2","timestamp":1756751124154},{"file_id":"1YaDeob5zxcJ6xQO26D2cav_vqM4XAP_e","timestamp":1756744781379},{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1756236442835}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}